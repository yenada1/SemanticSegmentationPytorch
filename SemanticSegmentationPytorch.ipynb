{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AbTeDP5Tbou"
      },
      "source": [
        "# Segmentation\n",
        "\n",
        "There are different neural architectures for segmentation, but they all have the same structure:\n",
        "\n",
        "* **Encoder** 입력 이미지에서 특징을 추출\n",
        "* **Decoder** 특징을 클래스 수에 해당하는 동일한 크기와 채널 수를 가진 **마스크 이미지**로 변환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequsites\n",
        "\n",
        "To begin with, we will import required libraries, and check if there is GPU available for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T15:48:06.861688Z",
          "iopub.status.busy": "2022-04-08T15:48:06.861254Z",
          "iopub.status.idle": "2022-04-08T15:48:06.868219Z",
          "shell.execute_reply": "2022-04-08T15:48:06.867567Z",
          "shell.execute_reply.started": "2022-04-08T15:48:06.861644Z"
        },
        "id": "tv1T3XemFMpE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%pip install scikit-image\n",
        "%pip install torch==2.0.1 torchvision==0.15.2\n",
        "%pip install tqdm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm # 진행 상황 표시기를 추가\n",
        "import numpy as np\n",
        "import torch.nn.functional as F # PyTorch의 함수형 API를 사용\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "\n",
        "# 시드 설정의 중요성\n",
        "# 재현 가능성: 동일한 시드 값이 사용되면, 코드 실행 시 동일한 난수 생성 패턴이 유지됨\n",
        "#    모델 훈련 결과가 일관되게 유지되도록 함\n",
        "# 디버깅 용이성: 결과가 일관되면 디버깅이 훨씬 쉬워짐\n",
        "#    예를 들어, 모델이 특정 에포크에서 이상한 동작을 보일 경우, 같은 시드로 다시 실행하여 그 에포크의 상태를 쉽게 조사할 수 있음\n",
        "# 이 설정은 모델을 반복적으로 실행하면서 동일한 결과를 얻고자 할 때 유용\n",
        "#    PyTorch와 NumPy 모두 시드 설정을 통해 난수 생성의 일관성을 유지할 수 있음\n",
        "\n",
        "torch.manual_seed(42) # PyTorch의 난수 생성기의 시드를 42로 설정하여 실험의 재현 가능성을 보장\n",
        "np.random.seed(42) # NumPy의 난수 생성기의 시드를 42로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:32.933989Z",
          "iopub.status.busy": "2022-04-08T16:03:32.933733Z",
          "iopub.status.idle": "2022-04-08T16:03:32.937996Z",
          "shell.execute_reply": "2022-04-08T16:03:32.937366Z",
          "shell.execute_reply.started": "2022-04-08T16:03:32.933959Z"
        },
        "id": "xhSEogpDFMpK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "train_size = 0.9 # train_size: 전체 데이터셋 중 훈련에 사용할 데이터의 비율 - 0.9로 설정되었으므로 90%의 데이터를 훈련에 사용하고, 나머지 10%를 검증 또는 테스트에 사용\n",
        "lr = 1e-3 # 학습률\n",
        "weight_decay = 1e-6 # 가중치 감쇠 - L2 정규화 항을 통해 가중치를 줄이는 데 사용\n",
        "batch_size = 32 # 훈련 중 한 번에 처리할 데이터 샘플의 수를 의미\n",
        "epochs = 30 # 전체 데이터셋을 몇 번 반복하여 훈련할지를 의미"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4if75qwFMpJ"
      },
      "source": [
        "## The Dataset\n",
        "\n",
        "- 인간 모반의 더모스코픽 이미지에 대한 PH<sup>2</sup> 데이터베이스를 사용\n",
        "- 이 데이터 세트에는 전형적인 모반, 비정형 모반, 흑색종 등 세 가지 유형의 모반에 대한 200개의 이미지가 포함되어 있음\n",
        "- 모든 이미지에는 모반의 윤곽을 나타내는 해당 **마스크**도 포함되어 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:47:25.071036Z",
          "iopub.status.busy": "2022-04-08T16:47:25.070746Z",
          "iopub.status.idle": "2022-04-08T16:47:32.612115Z",
          "shell.execute_reply": "2022-04-08T16:47:32.611253Z",
          "shell.execute_reply.started": "2022-04-08T16:47:25.071005Z"
        },
        "id": "TkuYGLRKFMpK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# terminal에서 sudo apt-get install unrar\n",
        "\n",
        "!wget https://www.dropbox.com/s/k88qukc20ljnbuo/PH2Dataset.rar\n",
        "!unrar x -Y PH2Dataset.rar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 이제 데이터 세트를 로드하는 코드를 정의\n",
        "- 모든 이미지를 256x256 크기로 변환하고 데이터 세트를 훈련과 테스트 부분으로 분할\n",
        "- 이 함수는 모반의 윤곽을 나타내는 원본 이미지와 마스크가 각각 포함된 훈련 및 테스트 데이터 세트를 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rumy9ldAFteW"
      },
      "outputs": [],
      "source": [
        "def load_dataset(train_part, root='PH2Dataset'): # train_part 비율과 데이터가 위치한 루트 폴더를 인자로 받음\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    # PH2 Dataset images 폴더를 순회하면서 _Dermoscopic_Image로 끝나는 폴더에서 이미지를, _lesion으로 끝나는 폴더에서 마스크 이미지를 로드\n",
        "\n",
        "    for root, dirs, files in os.walk(os.path.join(root, 'PH2 Dataset images')):\n",
        "        if root.endswith('_Dermoscopic_Image'):\n",
        "            images.append(imread(os.path.join(root, files[0])))\n",
        "        if root.endswith('_lesion'):\n",
        "            masks.append(imread(os.path.join(root, files[0])))\n",
        "\n",
        "    # 로드한 이미지와 마스크를 (256, 256) 크기로 리사이즈\n",
        "    # 이미지는 (N, C, H, W) 형식으로 변환하고, 마스크는 이진화하여 (N, 1, H, W) 형식으로 변환\n",
        "\n",
        "    size = (256, 256)\n",
        "    images = torch.permute(torch.FloatTensor(np.array([resize(image, size, mode='constant', anti_aliasing=True,) for image in images])), (0, 3, 1, 2))\n",
        "    masks = torch.FloatTensor(np.array([resize(mask, size, mode='constant', anti_aliasing=False) > 0.5 for mask in masks])).unsqueeze(1)\n",
        "\n",
        "    # 데이터셋을 무작위로 섞고, train_part 비율에 따라 학습용 데이터와 테스트용 데이터로 나눔\n",
        "\n",
        "    indices = np.random.permutation(range(len(images)))\n",
        "    train_part = int(train_part * len(images))\n",
        "    train_ind = indices[:train_part]\n",
        "    test_ind = indices[train_part:]\n",
        "\n",
        "    # 학습 데이터셋과 테스트 데이터셋을 반환\n",
        "\n",
        "    train_dataset = (images[train_ind, :, :, :], masks[train_ind, :, :, :])\n",
        "    test_dataset = (images[test_ind, :, :, :], masks[test_ind, :, :, :])\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "train_dataset, test_dataset = load_dataset(train_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "데이터 집합의 일부 이미지를 플롯하여 어떻게 보이는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:58.259127Z",
          "iopub.status.busy": "2022-04-08T16:03:58.258819Z",
          "iopub.status.idle": "2022-04-08T16:03:58.266433Z",
          "shell.execute_reply": "2022-04-08T16:03:58.265489Z",
          "shell.execute_reply.started": "2022-04-08T16:03:58.259090Z"
        },
        "id": "jP2_-AjIFMpO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 주어진 데이터셋에서 이미지와 마스크를 시각화하는 기능을 수행\n",
        "\n",
        "def plotn(n, data, only_mask=False): # n은 표시할 이미지와 마스크의 수, data는 이미지와 마스크 데이터셋, only_mask는 마스크만 표시할지 여부를 결정하는 플래그\n",
        "    images, masks = data[0], data[1] # data에서 이미지와 마스크를 분리\n",
        "    fig, ax = plt.subplots(1, n) # 이미지를 표시할 서브플롯을 생성\n",
        "    fig1, ax1 = plt.subplots(1, n) # 마스크를 표시할 서브플롯을 생성\n",
        "    for i, (img, mask) in enumerate(zip(images, masks)): # 이미지를 순회하면서 표시\n",
        "        if i == n: # n개까지만 표시\n",
        "            break\n",
        "        if not only_mask: # only_mask가 False이면 이미지를 표시\n",
        "            ax[i].imshow(torch.permute(img, (1, 2, 0)))\n",
        "        else: # only_mask가 True이면 첫 번째 채널만 표시\n",
        "            ax[i].imshow(img[0])\n",
        "        ax1[i].imshow(mask[0]) # 마스크를 표시\n",
        "        ax[i].axis('off') # 축을 숨김\n",
        "        ax1[i].axis('off')\n",
        "    plt.show() # 플롯을 화면에 표시\n",
        "\n",
        "plotn(5, train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "신경망에 데이터를 공급하기 위해 데이터 로더가 필요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:58.247264Z",
          "iopub.status.busy": "2022-04-08T16:03:58.246853Z",
          "iopub.status.idle": "2022-04-08T16:03:58.256661Z",
          "shell.execute_reply": "2022-04-08T16:03:58.255964Z",
          "shell.execute_reply.started": "2022-04-08T16:03:58.247222Z"
        },
        "id": "rUGDAa61FMpN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# PyTorch의 DataLoader를 사용하여 학습 데이터셋과 테스트 데이터셋을 배치로 로드\n",
        "\n",
        "# torch.utils.data.DataLoader를 사용하여 학습 데이터셋의 데이터 로더를 만듦\n",
        "# list(zip(train_dataset[0], train_dataset[1])): 학습 이미지와 마스크를 쌍으로 묶어 리스트로 만듦\n",
        "# batch_size=batch_size: 배치 크기를 batch_size로 설정\n",
        "# shuffle=True: 데이터셋을 섞어서 배치를 만듭니다. 이는 모델 학습 시 데이터의 순서로 인한 편향을 방지\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(list(zip(train_dataset[0], train_dataset[1])), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# torch.utils.data.DataLoader를 사용하여 테스트 데이터셋의 데이터 로더를 만듦\n",
        "# list(zip(test_dataset[0], test_dataset[1])): 테스트 이미지와 마스크를 쌍으로 묶어 리스트로 만듦\n",
        "# batch_size=1: 배치 크기를 1로 설정 - 이는 보통 테스트 시 각 샘플을 개별적으로 평가하기 위해 사용\n",
        "# shuffle=False: 데이터셋을 섞지 않고 순서대로 배치를 만듦 - 이는 테스트 데이터의 순서를 유지하기 위해 사용\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(list(zip(test_dataset[0], test_dataset[1])), batch_size=1, shuffle=False)\n",
        "\n",
        "# train_dataloader와 test_dataloader를 튜플로 묶어 dataloaders로 저장 - 이를 통해 학습과 테스트 데이터 로더를 한 번에 관리\n",
        "\n",
        "dataloaders = (train_dataloader, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORmas8XhYfS8"
      },
      "source": [
        "## SegNet\n",
        "\n",
        "- 가장 간단한 인코더-디코더 아키텍처는 **SegNet**이라고 함\n",
        "- 인코더에는 컨볼루션과 풀링이 포함된 표준 CNN을 사용하고, 디코더에는 컨볼루션과 업샘플링이 포함된 디컨볼루션 CNN을 사용\n",
        "- 또한 다층 네트워크를 성공적으로 훈련하기 위해 배치 정규화에 의존"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:59.239435Z",
          "iopub.status.busy": "2022-04-08T16:03:59.239186Z",
          "iopub.status.idle": "2022-04-08T16:03:59.257319Z",
          "shell.execute_reply": "2022-04-08T16:03:59.256388Z",
          "shell.execute_reply.started": "2022-04-08T16:03:59.239401Z"
        },
        "id": "QDsSrmbeTbp9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# PyTorch를 사용하여 정의된 SegNet 아키텍처\n",
        "# SegNet은 이미지 분할을 위한 신경망\n",
        "# SegNet의 인코더-디코더 구조를 정의\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # 인코더 (Encoder)\n",
        "        # 이미지의 중요한 특징을 추출\n",
        "        # 여러 개의 Conv2d, ReLU, BatchNorm2d, 그리고 MaxPool2d 레이어로 구성\n",
        "        # 각 인코딩 단계는 컨볼루션 연산 후 활성화 함수(ReLU)와 배치 정규화를 거치고, 마지막으로 맥스 풀링을 통해 차원을 축소\n",
        "        \n",
        "        self.enc_conv0 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3,3), padding=1)\n",
        "        self.act0 = nn.ReLU()\n",
        "        self.bn0 = nn.BatchNorm2d(16)\n",
        "        self.pool0 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.enc_conv1 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.enc_conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 =  nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.enc_conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=1)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 =  nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        # 병목 (Bottleneck)\n",
        "        # 인코더와 디코더 사이에서 가장 중요한 특징을 압축하고 전달\n",
        "        # 하나의 Conv2d 레이어로 구성\n",
        "\n",
        "        self.bottleneck_conv = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding=1)\n",
        "        \n",
        "        # 디코더 (Decoder)\n",
        "        # 인코더에서 추출된 특징을 사용하여 원본 이미지의 해상도와 유사하게 복원\n",
        "        # 여러 개의 업샘플링(UpsamplingBilinear2d)과 Conv2d, ReLU, BatchNorm2d 레이어로 구성\n",
        "        # 마지막 레이어는 컨볼루션을 통해 출력 채널을 1로 줄이고, 시그모이드 활성화 함수를 통해 결과를 이진화\n",
        "\n",
        "        self.upsample0 =  nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "        self.dec_conv0 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(3,3), padding=1)\n",
        "        self.dec_act0 = nn.ReLU()\n",
        "        self.dec_bn0 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.upsample1 =  nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "        self.dec_conv1 =  nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3), padding=1)\n",
        "        self.dec_act1 = nn.ReLU()\n",
        "        self.dec_bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "        \n",
        "        self.dec_conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(3,3), padding=1)\n",
        "        self.dec_act2 = nn.ReLU()\n",
        "        self.dec_bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.upsample3 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "        self.dec_conv3 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=(1,1))\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Forward 함수\n",
        "    # 입력 이미지를 받아 인코더를 거친 후 병목을 통해 압축하고, 디코더를 거쳐 출력 이미지를 생성 - 이 함수는 모델의 순전파 과정을 정의\n",
        "\n",
        "    def forward(self, x):\n",
        "        e0 = self.pool0(self.bn0(self.act0(self.enc_conv0(x))))\n",
        "        e1 = self.pool1(self.bn1(self.act1(self.enc_conv1(e0))))\n",
        "        e2 = self.pool2(self.bn2(self.act2(self.enc_conv2(e1))))\n",
        "        e3 = self.pool3(self.bn3(self.act3(self.enc_conv3(e2))))\n",
        "\n",
        "        b = self.bottleneck_conv(e3)\n",
        "\n",
        "        d0 = self.dec_bn0(self.dec_act0(self.dec_conv0(self.upsample0(b))))\n",
        "        d1 = self.dec_bn1(self.dec_act1(self.dec_conv1(self.upsample1(d0))))\n",
        "        d2 = self.dec_bn2(self.dec_act2(self.dec_conv2(self.upsample2(d1))))\n",
        "        d3 = self.sigmoid(self.dec_conv3(self.upsample3(d2)))\n",
        "        return d3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Segmentation에 사용되는 손실 함수\n",
        "- autoencoder에서는 두 이미지 간의 유사성을 측정해야 하며, 이를 위해 평균 제곱 오차를 사용할 수 있음\n",
        "- Segmentation에서 대상 마스크 이미지의 각 픽셀은 클래스 번호(3차원을 따라 한 번 핫 인코딩됨)를 나타내므로 분류에 특화된 손실 함수인 교차 엔트로피 손실(모든 픽셀에 평균을 낸 값)을 사용\n",
        "- 마스크가 2진수인 경우에는 **2진수 교차 엔트로피 손실**(BCE)을 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:59.259154Z",
          "iopub.status.busy": "2022-04-08T16:03:59.258856Z",
          "iopub.status.idle": "2022-04-08T16:03:59.284201Z",
          "shell.execute_reply": "2022-04-08T16:03:59.283559Z",
          "shell.execute_reply.started": "2022-04-08T16:03:59.259108Z"
        },
        "id": "2GoR8-huFMpn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# SegNet 모델을 생성하고, 최적화 함수와 손실 함수를 설정하는 과정\n",
        "\n",
        "model = SegNet().to(device) # # SegNet 모델 생성 및 장치로 이동\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) # # Adam 최적화 함수 설정\n",
        "loss_fn = nn.BCEWithLogitsLoss() # # 이진 교차 엔트로피 손실 함수 설정 (로그잇 함수와 함께 사용)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "학습 루프는 일반적인 방식으로 정의됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:59.286008Z",
          "iopub.status.busy": "2022-04-08T16:03:59.285826Z",
          "iopub.status.idle": "2022-04-08T16:03:59.298404Z",
          "shell.execute_reply": "2022-04-08T16:03:59.297656Z",
          "shell.execute_reply.started": "2022-04-08T16:03:59.285986Z"
        },
        "id": "HQ_UFglyTbqM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# SegNet 모델을 학습하는 train 함수를 정의\n",
        "# 이 함수는 주어진 데이터 로더, 모델, 손실 함수, 최적화 함수 및 에포크 수를 사용하여 모델을 학습하고 검증\n",
        "# 진행 상황은 tqdm 라이브러리를 통해 시각적으로 표시\n",
        "\n",
        "def train(dataloaders, model, loss_fn, optimizer, epochs, device): # 주어진 인자를 사용하여 모델을 학습\n",
        "    tqdm_iter = tqdm(range(epochs)) # 학습 진행을 시각적으로 표시하기 위해 tqdm 라이브러리를 사용\n",
        "    train_dataloader, test_dataloader = dataloaders[0], dataloaders[1]\n",
        "\n",
        "    for epoch in tqdm_iter: # 지정된 에포크 수만큼 반복\n",
        "        model.train() # 모델을 학습 모드로 설정\n",
        "        train_loss = 0.0 # 학습 손실 초기화\n",
        "        test_loss = 0.0 # 테스트 손실 초기화\n",
        "\n",
        "        for batch in train_dataloader: # 학습 데이터 로더에서 배치를 반복\n",
        "            imgs, labels = batch\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            preds = model(imgs) # 모델에 이미지 전달하여 예측 생성\n",
        "            loss = loss_fn(preds, labels) # 손실 계산\n",
        "\n",
        "            optimizer.zero_grad() # 옵티마이저 초기화\n",
        "            loss.backward() # 역전파\n",
        "            optimizer.step() # 가중치 업데이트\n",
        "\n",
        "            train_loss += loss.item() # 배치 손실을 학습 손실에 추가\n",
        "\n",
        "        model.eval() # 모델을 평가 모드로 설정\n",
        "        with torch.no_grad(): # 검증 단계에서는 그래디언트를 계산하지 않음\n",
        "            for batch in test_dataloader: # 테스트 데이터 로더에서 배치를 반복\n",
        "                imgs, labels = batch\n",
        "                imgs = imgs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                preds = model(imgs)\n",
        "                loss = loss_fn(preds, labels)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_dataloader) # 학습 손실 평균\n",
        "        test_loss /= len(test_dataloader) # 테스트 손실 평균\n",
        "\n",
        "        tqdm_dct = {'train loss:': train_loss, 'test loss:': test_loss} # 손실 값을 딕셔너리에 저장\n",
        "        tqdm_iter.set_postfix(tqdm_dct, refresh=True) # tqdm 진행 표시줄을 업데이트\n",
        "        tqdm_iter.refresh() # tqdm 진행 표시줄을 새로 고침"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-04-08T16:03:59.302207Z",
          "iopub.status.busy": "2022-04-08T16:03:59.301979Z",
          "iopub.status.idle": "2022-04-08T16:17:44.792683Z",
          "shell.execute_reply": "2022-04-08T16:17:44.791975Z",
          "shell.execute_reply.started": "2022-04-08T16:03:59.302184Z"
        },
        "id": "MsgM_kZRFMpo",
        "outputId": "8ff2de4a-ad8d-4b57-bdeb-ecaa90f742e2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# train 함수를 실행하여 SegNet 모델을 학습\n",
        "# 주어진 데이터 로더, 모델, 손실 함수, 최적화 함수, 에포크 수, 그리고 장치 정보를 사용하여 학습 과정을 진행\n",
        "\n",
        "train(dataloaders, model, loss_fn, optimizer, epochs, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "모델을 평가하기 위해 여러 이미지에 대한 대상 마스크와 예상 마스크를 플로팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "execution": {
          "iopub.execute_input": "2022-04-08T16:17:44.795590Z",
          "iopub.status.busy": "2022-04-08T16:17:44.794942Z",
          "iopub.status.idle": "2022-04-08T16:17:45.663916Z",
          "shell.execute_reply": "2022-04-08T16:17:45.663160Z",
          "shell.execute_reply.started": "2022-04-08T16:17:44.795550Z"
        },
        "id": "FXvR7P1FFMpo",
        "outputId": "16b1f56d-93e0-48a0-d0c2-a8214b537741",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# SegNet 모델을 평가 모드로 설정하고 테스트 데이터셋에 대해 예측을 생성한 후, 일부 예측된 마스크를 시각화\n",
        "# plotn 함수는 only_mask=True 설정으로 예측된 마스크만 시각화\n",
        "\n",
        "model.eval() # 모델을 평가 모드로 설정 - 평가 모드에서는 드롭아웃 및 배치 정규화 레이어가 학습 시와 다르게 작동\n",
        "predictions = [] # 리스트를 초기화\n",
        "image_mask = []\n",
        "plots = 5\n",
        "images, masks = test_dataset[0], test_dataset[1] # images와 masks는 테스트 데이터셋에서 이미지를 가져옮\n",
        "for i, (img, mask) in enumerate(zip(images, masks)): # 테스트 데이터셋에서 일부 이미지를 반복\n",
        "    if i == plots: # 시각화할 이미지 수를 plots로 제한\n",
        "        break\n",
        "    img = img.to(device).unsqueeze(0) # 이미지를 지정된 장치로 이동시키고 배치 차원을 추가\n",
        "    predictions.append((model(img).detach().cpu()[0] > 0.5).float()) # 모델에 이미지를 전달하여 예측을 생성하고, 시그모이드 활성화 함수를 적용한 후 이진화하여 리스트에 추가\n",
        "    image_mask.append(mask) # 실제 마스크를 리스트에 추가\n",
        "plotn(plots, (predictions, image_mask), only_mask=True) # plotn 함수를 호출하여 예측된 마스크와 실제 마스크를 시각화 - only_mask=True로 설정하여 마스크만 표시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SemanticSegmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
